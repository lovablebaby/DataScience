{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with SVMs\n",
    "### make your modeling high-performance as much as you can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터 성능 문제로 튜닝이 어려워 어떤 사람이 올려놓은 깃헙을 참고했습니다\n",
    "\n",
    "깃헙은 [여기](https://github.com/ksopyla/svm_mnist_digit_classification)를 참고했습니다.\n",
    "\n",
    "- 코드 영어 작성 : 깃헙 주인\n",
    "- 코드 한글 작성 : 본인이 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Krzysztof Sopyla <krzysztofsopyla@gmail.com>\n",
    "# https://ksopyla.com\n",
    "# License: MIT\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 측정 시간을 가늠해보기 위해 시간 관련 라이브러리 호출\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "#fetch original mnist dataset\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# import custom module\n",
    "# 혼동행렬 시각화를 위해 모듈을 하나 만들었습니다. (아래에 있음)\n",
    "from mnist_helpers import *\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original', data_home='./')\n",
    "\n",
    "#minist object contains: data, COL_NAMES, DESCR, target fields\n",
    "#you can check it by running\n",
    "mnist.keys()\n",
    "\n",
    "#data field is 70k x 784 array, each row represents pixels from 28x28=784 image\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "# Let's have a look at the random 16 images, \n",
    "# We have to reshape each data row, from flat array of 784 int to 28x28 2D array\n",
    "\n",
    "#pick  random indexes from 0 to size of our dataset\n",
    "show_some_digits(images,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼동 행렬을 그려주는 모듈을 따로 만듬\n",
    "\n",
    "mnist_helpers.py 이름으로 생성\n",
    "\n",
    "~~~\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "\n",
    "def show_some_digits(images, targets, sample_size=24, title_text='Digit {}' ):\n",
    "    '''\n",
    "    Visualize random digits in a grid plot\n",
    "    images - array of flatten gidigs [:,784]\n",
    "    targets - final labels\n",
    "    '''\n",
    "    nsamples=sample_size\n",
    "    rand_idx = np.random.choice(images.shape[0],nsamples)\n",
    "    images_and_labels = list(zip(images[rand_idx], targets[rand_idx]))\n",
    "\n",
    "\n",
    "    img = plt.figure(1, figsize=(15, 12), dpi=160)\n",
    "    for index, (image, label) in enumerate(images_and_labels):\n",
    "        plt.subplot(np.ceil(nsamples/6.0), 6, index + 1)\n",
    "        plt.axis('off')\n",
    "        #each image is flat, we have to reshape to 2D array 28x28-784\n",
    "        plt.imshow(image.reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title(title_text.format(label))\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Plots confusion matrix, \n",
    "    \n",
    "    cm - confusion matrix\n",
    "    \"\"\"\n",
    "    plt.figure(1, figsize=(15, 12), dpi=160)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')    \n",
    "    \n",
    "\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "def plot_param_space_scores(scores, C_range, gamma_range):\n",
    "    \"\"\"\n",
    "    Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores - 2D numpy array with accuracies\n",
    "    \n",
    "    \"\"\"\n",
    "    #\n",
    "    # The score are encoded as colors with the hot colormap which varies from dark\n",
    "    # red to bright yellow. As the most interesting scores are all located in the\n",
    "    # 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "    # as to make it easier to visualize the small variations of score values in the\n",
    "    # interesting range while not brutally collapsing all the low score values to\n",
    "    # the same color.\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.jet,\n",
    "               norm=MidpointNormalize(vmin=0.5, midpoint=0.9))\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    plt.title('Validation accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "~~~ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 그리드서치에 관련된 코드.\n",
    "\n",
    "#### 그리드서치를 하면 최적의 규제값 C와 감마값을 찾을 수 있지만 연산에 드는 시간이 엄청나기에 코드를 대신 붙여놓습니다.\n",
    "\n",
    "~~~\n",
    "############### Classification with grid search ##############\n",
    "# If you don't want to wait, comment this section and uncommnet section below with\n",
    "# standalone SVM classifier\n",
    "\n",
    "# Warning! It takes really long time to compute this about 2 days\n",
    "\n",
    "# Create parameters grid for RBF kernel, we have to set C and gamma\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# generate matrix with all gammas\n",
    "# [ [10^-4, 2*10^-4, 5*10^-4], \n",
    "#   [10^-3, 2*10^-3, 5*10^-3],\n",
    "#   ......\n",
    "#   [10^3, 2*10^3, 5*10^3] ]\n",
    "#gamma_range = np.outer(np.logspace(-4, 3, 8),np.array([1,2, 5]))\n",
    "gamma_range = np.outer(np.logspace(-3, 0, 4),np.array([1,5]))\n",
    "gamma_range = gamma_range.flatten()\n",
    "\n",
    "# generate matrix with all C\n",
    "#C_range = np.outer(np.logspace(-3, 3, 7),np.array([1,2, 5]))\n",
    "C_range = np.outer(np.logspace(-1, 1, 3),np.array([1,5]))\n",
    "# flatten matrix, change to 1D numpy array\n",
    "C_range = C_range.flatten()\n",
    "\n",
    "parameters = {'kernel':['rbf'], 'C':C_range, 'gamma': gamma_range}\n",
    "\n",
    "svm_clsf = svm.SVC()\n",
    "grid_clsf = GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=1, verbose=2)\n",
    "\n",
    "\n",
    "start_time = dt.datetime.now()\n",
    "print('Start param searching at {}'.format(str(start_time)))\n",
    "\n",
    "grid_clsf.fit(X_train, y_train)\n",
    "\n",
    "elapsed_time= dt.datetime.now() - start_time\n",
    "print('Elapsed time, param searching {}'.format(str(elapsed_time)))\n",
    "sorted(grid_clsf.cv_results_.keys())\n",
    "\n",
    "classifier = grid_clsf.best_estimator_\n",
    "params = grid_clsf.best_params_\n",
    "\n",
    "\n",
    "\n",
    "scores = grid_clsf.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n",
    "\n",
    "plot_param_space_scores(scores, C_range, gamma_range)\n",
    "######################### end grid section #############\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------- classification begins -----------------\n",
    "#scale data for [0,255] -> [0,1]\n",
    "#sample smaller size for testing\n",
    "#rand_idx = np.random.choice(images.shape[0],10000)\n",
    "#X_data =images[rand_idx]/255.0\n",
    "#Y      = targets[rand_idx]\n",
    "\n",
    "# 각 벡터가 0~255 사이에 있으므로 0~1로 스케일링을 해서 연산의 범위를 줄인다\n",
    "#full dataset classification\n",
    "X_data = images/255.0\n",
    "Y = targets\n",
    "\n",
    "#split data to train and test\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-05-08 22:10:57.354474\n",
      "Stop learning 2018-05-08 22:33:13.147571\n",
      "Elapsed learning 0:22:15.793097\n",
      "Classification report for classifier SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1024\n",
      "        1.0       0.99      0.99      0.99      1185\n",
      "        2.0       0.98      0.99      0.98      1051\n",
      "        3.0       0.98      0.98      0.98      1057\n",
      "        4.0       0.99      0.99      0.99       964\n",
      "        5.0       0.98      0.98      0.98       964\n",
      "        6.0       0.99      0.99      0.99      1085\n",
      "        7.0       0.99      0.98      0.99      1128\n",
      "        8.0       0.97      0.98      0.97      1037\n",
      "        9.0       0.98      0.97      0.98      1005\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10500\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[1014    0    2    0    0    2    2    0    1    3]\n",
      " [   0 1177    2    1    1    0    1    0    2    1]\n",
      " [   2    2 1037    2    0    0    0    2    5    1]\n",
      " [   0    0    3 1035    0    5    0    6    6    2]\n",
      " [   0    0    1    0  957    0    1    2    0    3]\n",
      " [   1    1    0    4    1  947    4    0    5    1]\n",
      " [   2    0    1    0    2    0 1076    0    4    0]\n",
      " [   1    1    8    1    1    0    0 1110    2    4]\n",
      " [   0    4    2    4    1    6    0    1 1018    1]\n",
      " [   3    1    0    7    5    2    0    4    9  974]]\n",
      "Accuracy=0.9852380952380952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "################ Classifier with good params ###########\n",
    "# Create a classifier: a support vector classifier\n",
    "\n",
    "param_C = 5\n",
    "param_gamma = 0.05\n",
    "classifier = svm.SVC(C=param_C,gamma=param_gamma)\n",
    "\n",
    "# We learn the digits on train part\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier.fit(X_train, y_train)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "\n",
    "\n",
    "########################################################-+\n",
    "# Now predict the value of the test\n",
    "expected = y_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "show_some_digits(X_test,predicted,title_text=\"Predicted {}\")\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "      \n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 최적의 감마값은 0.05, C값은 5\n",
    "### 돌려보니 대략적으로 98%의 정확도를 보인다.\n",
    "\n",
    "- 혼동 행렬에서 대각행렬 성분이 1을 1/ 2를 2라고 맞추었을 확률"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
