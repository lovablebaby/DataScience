{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NeuralNetwork Class: Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define NN class\n",
    "class NeuralNetwork(object):\n",
    "    # Initialize NN\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Nodes\n",
    "        self.in_nodes = input_nodes\n",
    "        self.hn_nodes = hidden_nodes\n",
    "        self.ot_nodes = output_nodes\n",
    "        # Learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Weight Matix\n",
    "        ## Weight, input layer to hidden layer\n",
    "        ## np.random.normal(center, standard_deviation, dimension)\n",
    "        self.wih = np.random.normal(0.0, pow(self.hn_nodes, -0.5), (self.hn_nodes, self.in_nodes))\n",
    "        ## Weight, hidden layer to output layer\n",
    "        self.who = np.random.normal(0.0, pow(self.ot_nodes, -0.5), (self.ot_nodes, self.hn_nodes))\n",
    "        \n",
    "        # Activation function\n",
    "        self.activation_function = lambda x: expit(x)\n",
    "        \n",
    "    # Training logic\n",
    "    def train(self, input_list, target_list):\n",
    "        # FeedForward\n",
    "        ## Transform list to 2-dimensional transposed ndarray(to column vector)\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        targets = np.array(target_list, ndmin=2).T\n",
    "        \n",
    "        ## Operate input signal to hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        ## Operate ouput signal from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        ## Operate hidden signal to output layer\n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        ## Operate output\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        # Back Propagation\n",
    "        ## Errors\n",
    "        output_errors = targets - output_outputs\n",
    "        ## Hidden layers' errors\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        ## Update weight between output and hidden layers\n",
    "        self.who += self.learning_rate * np.dot((output_errors * output_outputs * (1-output_outputs)),\n",
    "                                                np.transpose(hidden_outputs))\n",
    "        ## Update weight between hidden and input layers\n",
    "        self.wih += self.learning_rate * np.dot((hidden_errors * hidden_outputs * (1-hidden_outputs)),\n",
    "                                                np.transpose(inputs))\n",
    "    def query(self, input_list):\n",
    "        # Transform list to 2-dimensional transposed ndarray(to column vector)\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        # Input to hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # Outputs from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # Hidden to output layer\n",
    "        output_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # Outputs from output layer\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        return output_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "learning_rate = 0.3\n",
    "\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41815135],\n",
       "       [ 0.58738589],\n",
       "       [ 0.38196017]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the class\n",
    "n.query([1.2, 3.2, -1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralNetwork with MNIST dataset\n",
    "\n",
    "- explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traning dataset\n",
    "\n",
    "with open('./dataframe/[HYStudy 23th] mnist_train_100.csv','r') as f:\n",
    "    train_list=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label, 20*28 matrix\n",
    "train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Library to display data\n",
    "import matplotlib.pylab as plt # to use imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADWCAYAAADmbvjqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkEVEEqEBWUQkEf8HKCFxnAWhzbcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fcff2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display data\n",
    "fig, axes = plt.subplots(2,5, subplot_kw={\"xticks\":[], \"yticks\": []})\n",
    "## makes 2*5 matrix\n",
    "\n",
    "# axes.flat : returns the axes as 1-dimensional(flay) array\n",
    "for ax, i in zip(axes.flat, range(0, 10)):\n",
    "    all_values = train_list[i].split(',')\n",
    "    # string to float, all_values[0] = label, transform to 28*28 matrix\n",
    "    image_array = np.asfarray(all_values[1:]).reshape(28, 28)\n",
    "    ax.imshow(image_array, cmap=\"Greys\")\n",
    "    ax.set_title(i)\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1102925c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,124,253,255,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,244,251,253,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,127,251,251,253,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,236,251,211,31,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,228,251,251,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,155,253,253,189,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,253,251,235,66,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,205,253,251,126,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,104,251,253,184,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,240,251,193,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,253,253,253,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,151,251,251,251,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,221,251,251,172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,234,251,251,196,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,251,251,89,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,159,255,253,253,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,228,253,247,140,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,251,253,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,251,253,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,193,253,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display \"1\" data(with grid)\n",
    "all_values = train_list[3].split(',')\n",
    "\n",
    "# String to float, all_values[0] = label, transform to 28*28\n",
    "image_array = np.asfarray(all_values[1:]).reshape(28, 28)\n",
    "\n",
    "# draw image\n",
    "plt.imshow(image_array, cmap=\"Greys\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Label {}\".format(all_values[0]))\n",
    "plt.show()\n",
    "\n",
    "train_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.49141176  0.99223529\n",
      "  1.          0.25458824  0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.38270588  0.95729412\n",
      "  0.98447059  0.99223529  0.25070588  0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.50305882\n",
      "  0.98447059  0.98447059  0.99223529  0.25070588  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.274\n",
      "  0.92623529  0.98447059  0.82917647  0.13035294  0.04105882  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.24294118\n",
      "  0.89517647  0.98447059  0.98447059  0.37494118  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.61176471  0.99223529  0.99223529  0.74376471  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.08764706  0.99223529  0.98447059  0.92235294  0.26623529  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.13423529  0.80588235  0.99223529  0.98447059  0.49917647  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.41376471  0.98447059  0.99223529  0.72435294  0.06823529  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.32058824  0.94176471  0.98447059  0.75929412  0.09929412  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.13423529  0.99223529  0.99223529  0.99223529  0.62729412  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.59623529  0.98447059  0.98447059  0.98447059  0.16141176  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.19635294  0.868       0.98447059  0.98447059  0.67776471  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.91847059  0.98447059  0.98447059  0.77094118  0.05658824  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.99223529  0.98447059  0.98447059  0.35552941  0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.62729412  1.          0.99223529  0.99223529  0.13035294  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.19635294  0.89517647  0.99223529  0.96894118  0.55352941  0.04105882\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.25847059  0.98447059  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.25847059  0.98447059  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.10317647  0.75929412  0.99223529  0.86411765  0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01\n",
      "  0.01        0.01        0.01        0.01        0.01        0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# Normailize RGB Values\n",
    "# +0.01 to prevent '0' as output\n",
    "# '0' input makes activation function's output to '0'\n",
    "\n",
    "norm_input = (np.asfarray(all_values[1:]) / 255 * 0.99 ) +0.01\n",
    "print(norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.99,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make output label array to put in NN\n",
    "# range must to be 0 < X < 1 (Sigmoid) <- adjust weight\n",
    "\n",
    "out_nodes = 10\n",
    "\n",
    "# Target value(label)\n",
    "# 1 -> 0.99, 0 -> 0.01 to satisty constraint\n",
    "\n",
    "targets = np.zeros(out_nodes) + 0.01\n",
    "\n",
    "# all_values[0] = label\n",
    "targets[int(all_values[0])] = 0.99\n",
    "\n",
    "# label = 1(index[1]=0.99)\n",
    "targets ## index[1]=0.99 means. the # is 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define network structure\n",
    "\n",
    "input_nodes = 784  # data = 28 * 28\n",
    "\n",
    "# the number of hidden nodes : choose heuristically\n",
    "# mush be smaller than input nodes to extract core feature\n",
    "# Properly larget than output nodes\n",
    "\n",
    "hidden_nodes = 100\n",
    "\n",
    "# the number of output nodes : same as the number of labels\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.3\n",
    "\n",
    "# make instance of NN\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NN\n",
    "for record in train_list:\n",
    "    # Split the csv data by seperator ','\n",
    "    all_values = record.split(',')\n",
    "    # Normalize input values\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01\n",
    "    # Create target value\n",
    "    targets = np.zeros(output_nodes) + 0.01\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load thest dataset\n",
    "with open('./dataframe/[HYStudy 23th] mnist_test_10.csv', 'r') as f:\n",
    "    test_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is 7\n"
     ]
    }
   ],
   "source": [
    "# test 1st data\n",
    "test_values = test_list[0].split(',')\n",
    "print(\"Correct answer is\", test_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-49-481d677a1d58>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-481d677a1d58>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(\"Predicted level is\",np.argmax(ans)\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Send query with nomalized values\n",
    "ans = n.query((np.asfarray(test_values[1:]) / 255.0 * 0.99) + 0.01)\n",
    "\n",
    "print(ans)\n",
    "print(\"maximum values is {} and index is {}\".format(max(ans), np.argmax(ans)))\n",
    "print(\"Predicted level is\",np.argmax(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
