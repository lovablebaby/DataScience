{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Neural Network\n",
    "## Adjusting hidden layer, node and hyperparameter tuning task\n",
    "#### (Key Perfomance Index; above 95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata(\"MNIST original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.64328403\n",
      "Iteration 2, loss = 0.69258679\n",
      "Iteration 3, loss = 0.49179304\n",
      "Iteration 4, loss = 0.40058948\n",
      "Iteration 5, loss = 0.34427115\n",
      "Iteration 6, loss = 0.30554064\n",
      "Iteration 7, loss = 0.27432320\n",
      "Iteration 8, loss = 0.25046827\n",
      "Iteration 9, loss = 0.23355208\n",
      "Iteration 10, loss = 0.21597519\n",
      "Iteration 11, loss = 0.20352474\n",
      "Iteration 12, loss = 0.19143280\n",
      "Iteration 13, loss = 0.18155553\n",
      "Iteration 14, loss = 0.17326195\n",
      "Iteration 15, loss = 0.16459801\n",
      "Iteration 16, loss = 0.15687100\n",
      "Iteration 17, loss = 0.14963603\n",
      "Iteration 18, loss = 0.14324683\n",
      "Iteration 19, loss = 0.13798726\n",
      "Iteration 20, loss = 0.13232767\n",
      "Iteration 21, loss = 0.12778109\n",
      "Iteration 22, loss = 0.12259860\n",
      "Iteration 23, loss = 0.11995417\n",
      "Iteration 24, loss = 0.11591710\n",
      "Iteration 25, loss = 0.11116964\n",
      "Iteration 26, loss = 0.10822218\n",
      "Iteration 27, loss = 0.10557730\n",
      "Iteration 28, loss = 0.10164319\n",
      "Iteration 29, loss = 0.09956818\n",
      "Iteration 30, loss = 0.09592378\n",
      "Iteration 31, loss = 0.09381182\n",
      "Iteration 32, loss = 0.09195459\n",
      "Iteration 33, loss = 0.08919907\n",
      "Iteration 34, loss = 0.08725847\n",
      "Iteration 35, loss = 0.08453911\n",
      "Iteration 36, loss = 0.08275992\n",
      "Iteration 37, loss = 0.08003726\n",
      "Iteration 38, loss = 0.07982713\n",
      "Iteration 39, loss = 0.07619451\n",
      "Iteration 40, loss = 0.07428147\n",
      "Iteration 41, loss = 0.07369668\n",
      "Iteration 42, loss = 0.07180921\n",
      "Iteration 43, loss = 0.06922908\n",
      "Iteration 44, loss = 0.06787764\n",
      "Iteration 45, loss = 0.06639930\n",
      "Iteration 46, loss = 0.06469823\n",
      "Iteration 47, loss = 0.06254790\n",
      "Iteration 48, loss = 0.06100415\n",
      "Iteration 49, loss = 0.06080363\n",
      "Iteration 50, loss = 0.05944666\n",
      "Iteration 51, loss = 0.05686005\n",
      "Iteration 52, loss = 0.05593074\n",
      "Iteration 53, loss = 0.05465408\n",
      "Iteration 54, loss = 0.05422940\n",
      "Iteration 55, loss = 0.05239721\n",
      "Iteration 56, loss = 0.05074348\n",
      "Iteration 57, loss = 0.05057203\n",
      "Iteration 58, loss = 0.04965497\n",
      "Iteration 59, loss = 0.04778031\n",
      "Iteration 60, loss = 0.04744600\n",
      "Iteration 61, loss = 0.04618352\n",
      "Iteration 62, loss = 0.04414587\n",
      "Iteration 63, loss = 0.04349592\n",
      "Iteration 64, loss = 0.04311829\n",
      "Iteration 65, loss = 0.04261639\n",
      "Iteration 66, loss = 0.04247900\n",
      "Iteration 67, loss = 0.04200548\n",
      "Iteration 68, loss = 0.03913215\n",
      "Iteration 69, loss = 0.03777083\n",
      "Iteration 70, loss = 0.03806852\n",
      "Iteration 71, loss = 0.03634570\n",
      "Iteration 72, loss = 0.03589108\n",
      "Iteration 73, loss = 0.03579938\n",
      "Iteration 74, loss = 0.03381073\n",
      "Iteration 75, loss = 0.03509066\n",
      "Iteration 76, loss = 0.03204014\n",
      "Iteration 77, loss = 0.03269142\n",
      "Iteration 78, loss = 0.03133663\n",
      "Iteration 79, loss = 0.03077229\n",
      "Iteration 80, loss = 0.03001999\n",
      "Iteration 81, loss = 0.03116522\n",
      "Iteration 82, loss = 0.02853221\n",
      "Iteration 83, loss = 0.02896826\n",
      "Iteration 84, loss = 0.02729125\n",
      "Iteration 85, loss = 0.02771906\n",
      "Iteration 86, loss = 0.02587885\n",
      "Iteration 87, loss = 0.02685891\n",
      "Iteration 88, loss = 0.02497806\n",
      "Iteration 89, loss = 0.02671282\n",
      "Iteration 90, loss = 0.02387557\n",
      "Iteration 91, loss = 0.02334869\n",
      "Iteration 92, loss = 0.02335628\n",
      "Iteration 93, loss = 0.02219152\n",
      "Iteration 94, loss = 0.02308837\n",
      "Iteration 95, loss = 0.02118786\n",
      "Iteration 96, loss = 0.02107821\n",
      "Iteration 97, loss = 0.02026826\n",
      "Iteration 98, loss = 0.02130479\n",
      "Iteration 99, loss = 0.02238194\n",
      "Iteration 100, loss = 0.01983353\n",
      "Iteration 101, loss = 0.02052940\n",
      "Iteration 102, loss = 0.01808326\n",
      "Iteration 103, loss = 0.01681765\n",
      "Iteration 104, loss = 0.01852669\n",
      "Iteration 105, loss = 0.01883354\n",
      "Iteration 106, loss = 0.01668557\n",
      "Iteration 107, loss = 0.01656474\n",
      "Iteration 108, loss = 0.01608837\n",
      "Iteration 109, loss = 0.01579224\n",
      "Iteration 110, loss = 0.01413606\n",
      "Iteration 111, loss = 0.01488894\n",
      "Iteration 112, loss = 0.01574066\n",
      "Iteration 113, loss = 0.01399378\n",
      "Iteration 114, loss = 0.01494870\n",
      "Iteration 115, loss = 0.01442730\n",
      "Iteration 116, loss = 0.01322085\n",
      "Iteration 117, loss = 0.01311421\n",
      "Iteration 118, loss = 0.01368863\n",
      "Iteration 119, loss = 0.01134618\n",
      "Iteration 120, loss = 0.01206317\n",
      "Iteration 121, loss = 0.01221091\n",
      "Iteration 122, loss = 0.01402757\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30),\n",
       "       learning_rate='constant', learning_rate_init=0.0001, max_iter=500,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation = 'relu', hidden_layer_sizes = (30,30,30,30,30,30,30,30,30,30,30),\n",
    "                    solver=\"adam\",\n",
    "                    learning_rate_init = 0.0001, \n",
    "                    max_iter = 500, verbose = 1)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.993967\n",
      "Test set score: 0.951900\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
