{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow dev summit x ModuLABs\n",
    "\n",
    "- 2018.04.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Robot Learning : 최석원님\n",
    "Alex (google) 자료 참고 (구글 텐서플로우 데브서밋 2018 https://www.youtube.com/watch?v=nQ1Ev9Inqco)\n",
    "\n",
    "================================================================\n",
    "\n",
    "### Robot Grasping : 로봇 팔로 물체 잡아 올리기!\n",
    "- 잡을 확률을 구해서 작동하는 것\n",
    "- RGB 카메라로 사물을 인식함. CNN + Manual(수동)으로 함께 학습시킴\n",
    "\n",
    "\n",
    "\n",
    "### 문제\n",
    "테스팅할때는 90%였는데 실제로 하니 23%이 나오는 경우가..\n",
    "\n",
    "### Feature level domain adaptation & Pixel level domain adaptation\n",
    "FLDA : similarity를 계산\n",
    "real data에서 온건지 simulation data에서 온건지 모르도록 학습을 시켜서 성능을 높일 수 있다.\n",
    "\n",
    "PLDA : Simulator - > Generator -> real-like -> Task model\n",
    "제너레이터에 넣으면 좀더 현실게 가깝게(Real-like), GAN처럼 학습을 시킴\n",
    "\n",
    "- 근데 이렇게 있는데도 불구하고 feature lvevel domain과 pixel level domian은 둘다 현실에서 쓰지 않는다.\n",
    "\n",
    "케이스를 3개로 나눠서,\n",
    "1. 시뮬레이터 데이터로 학습\n",
    "2. 실제 데이터로 학습\n",
    "3. 두개를 섞어서 학습\n",
    "\n",
    "데이터가 많아질수록 성능이 조금씩 상승했는데 3번이 제일 성능도 높고 올라가는 부분도 많았음.\n",
    "\n",
    "또한 실제 데이터를 쓰는 비용은 비싸다. 3번을 하면 더 적은 데이터 양으로 데이터 양이 더 많은 2번 케이스보다 좋은 성능을 내기도 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data / Eager Execution : 김보섭님\n",
    "\n",
    "- tf.data -> input과 output의 중요성\n",
    "- eager execution -> 파이토치와 견줄 동적 프로그래밍 사용 가능하도록 새로 만든 기능\n",
    "\n",
    "tf.placeholder 써서 모델을 구축한다. 저용량일때 가능.\n",
    "feed_dict할때 성능이 낮아질 수 있다.\n",
    "\n",
    "QueueRunner는 성능이 좋지만 클라이언트 스레드에서 런되고 구성하기 좀 복잡함\n",
    "\n",
    "#### tf.data는\n",
    "\n",
    "- fast to keep up with GPUs and TPUs\n",
    "- flexible to handle diverse data sources and use cases\n",
    "- easy to use to democratize machine learning.\n",
    "\n",
    "ETL : Extract, Transform, Load\n",
    "\n",
    "간단하게 linear reg를 했다고 했을때, \n",
    "\n",
    "pandas를 써서 메모리에 올리게 되는데\n",
    "\n",
    "tf.data를 사용하게 ETL 구현이 가능하다. 함수형 프로그래밍같이.. (map, flatmap, etc) \n",
    "\n",
    "#### Eager Execution\n",
    "\n",
    "eager execution을 안쓸때는 session run 이 바로 필요한데\n",
    "\n",
    "쓰게되면 session 만들 필요가 없이 바로 프린트 가능함\n",
    "\n",
    "numpy와 심리스(?)함\n",
    "\n",
    "\n",
    "\n",
    "###### import tensorflow.contrib.eager as tfe\n",
    "##### tf.enable_eager_execution()\n",
    "\n",
    "- easier debugging!!!!\n",
    "- An intuitive interface\n",
    "- Natural control flow\n",
    "\n",
    "Say bye to \"placeholder, session, control dependencies, lazy loading, scopes..\"\n",
    "\n",
    "멀티연산이 안되기 때문에 프로토타입을 돌릴 때는 텐서가 훨씬 낫다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging with TensorBoard : 이준호님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이나 데이터에 대한 정보 시각화\n",
    "- 학습 과정 실시간 확인 가능\n",
    "- 기존의 트레이닝과 비교 가능\n",
    "- 쓰면 느려짐\n",
    "\n",
    "히스토그램 등으로 시각화 자료로 확인 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard debugger\n",
    "\n",
    "\n",
    "장점\n",
    "- 기존 텐서보드 열 때보다 매우 간단히 실행\n",
    "- 스텝바이 스텝으로 노드 실행\n",
    "- 깊은, 다양한 방법으로 학습모델 확인가능\n",
    "\n",
    "단점\n",
    "- 실행속도 느림\n",
    "- 알파버전이라 아직은 오류가 존재\n",
    "- 윈도우 안됨..(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반 디버거와 같이 break point 설정이 가능하다\n",
    "\n",
    "어떻게 학습이 되있는지 보이기 좋고\n",
    "\n",
    "신경망 시각화에 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF.DATA 신성진님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/modulabs/DeepNLP/blob/master/TF_Tutorial/TF.DATA_%EB%AA%A8%EB%91%90%EC%9D%98%EC%97%B0%EA%B5%AC%EC%86%8C.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요할때만 쓰고\n",
    "메모리 적게 사용하고, 스트리밍 서비스 용이."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코카콜라 텐서플로우 민규식님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in-browser 가능\n",
    "- 핸드폰 내장센서도 인풋데이터로 사용가능\n",
    "\n",
    "Tensorflos.js <- 자바스크립트 할줄알아야 하지만 할줄아는게 많다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex. Webcam controller PacMan (얼굴을 돌리면 알아서 돌아감, 얼굴이 컨트롤러임)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬을 통해서 만든 모델을 자바스크립트로도 돌려볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emojiscavengerhunt.withgoogle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 마케팅 \n",
    "##### 이전의 방법\n",
    "- proof of purchase (구매의 증거(쿠폰 등) 잘라서 회사에서 보내면 보상을 줌)\n",
    "- Sales promotion, loyalty marketing, 소비 데이터 수집\n",
    "\n",
    "\n",
    "##### 기술발전 이후\n",
    "- pin code\n",
    "- 근데 이게 안먹히니까 MNIST 데이터같이 숫자를 학습하기 시작함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
